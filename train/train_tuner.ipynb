{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9879ffeb-202e-430c-9cbb-3d5dd0a0f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec7c3c0-3d34-4a53-9d6d-42d3277de05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af94ca5c-aa92-4a2e-9057-691d34b8c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, HTML\n",
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb24d5d0-ca7c-4079-9af1-62d7ad7bd860",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(sys.path[0], '../..'))\n",
    "\n",
    "import endure.data.io as EndureIO\n",
    "import endure.lsm.cost_model as CostFunc\n",
    "\n",
    "from endure.ltune.data.generator import LTuneGenerator\n",
    "from endure.ltune.data.dataset import LTuneIterableDataSet\n",
    "from endure.lcm.model.builder import LearnedCostModelBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9889b78-8541-46c6-ab91-c3c7f643c3e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = EndureIO.Reader.read_config('../../endure.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91699a84-8105-4d9c-9c0f-814e31234fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicTuner(nn.Module):\n",
    "    def __init__(self, config: dict[str, ...]):\n",
    "        super().__init__()\n",
    "        self.params = config['ltune']['model']['classic']\n",
    "        size_ratio_range = (config['lsm']['size_ratio']['max']\n",
    "                            - config['lsm']['size_ratio']['min']\n",
    "                            + 1)\n",
    "\n",
    "        modules = []\n",
    "        num_feat = config['ltune']['model']['in_dim']\n",
    "        out_dim = 1 + size_ratio_range\n",
    "        modules.append(nn.Linear(num_feat, out_dim))\n",
    "        nn.init.xavier_normal_(modules[-1].weight)\n",
    "        modules.append(nn.LeakyReLU())\n",
    "        for _ in range(self.params['hidden_layers']):\n",
    "            modules.append(nn.Linear(out_dim, out_dim))\n",
    "            nn.init.xavier_normal_(modules[-1].weight)\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "        self.bits = nn.Sequential(\n",
    "            nn.Linear(out_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.size_ratio = nn.Sequential(\n",
    "            nn.Linear(out_dim, size_ratio_range),\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.layers = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x, temp=0.1, hard=False) -> torch.Tensor:\n",
    "        out = self.layers(x)\n",
    "        size_ratio = self.size_ratio(out)\n",
    "        size_ratio = nn.functional.gumbel_softmax(\n",
    "            size_ratio,\n",
    "            tau=temp,\n",
    "            hard=hard\n",
    "        )\n",
    "        print(f't gumbel = {size_ratio}')\n",
    "        h = self.bits(out)\n",
    "\n",
    "        return torch.concat([h, size_ratio], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42d5e3af-bbd5-4cc0-85f2-6b1fb4d951f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedCostModelLoss(torch.nn.Module):\n",
    "    def __init__(self, config: dict[str, ...], model_path: str):\n",
    "        super().__init__()\n",
    "        self.lcm_builder = LearnedCostModelBuilder(config)\n",
    "        self.model = self.lcm_builder.build_model()\n",
    "        _, extension = os.path.splitext(model_path)\n",
    "        is_checkpoint = (extension == '.checkpoint')\n",
    "        data = torch.load(os.path.join(config['io']['data_dir'], model_path))\n",
    "        if is_checkpoint:\n",
    "            data = data['model_state_dict']\n",
    "        status = self.model.load_state_dict(data)\n",
    "        \n",
    "        # self._mean = torch.Tensor(config['lcm']['data']['mean_bias'])\n",
    "        # self._std = torch.Tensor(config['lcm']['data']['std_bias'])\n",
    "        assert (len(status.missing_keys) == 0)\n",
    "        assert (len(status.unexpected_keys) == 0)\n",
    "\n",
    "    def forward(self, pred, label):\n",
    "        # For learned cost model loss, pred is the DB configuration, label is\n",
    "        # the workload\n",
    "        bpe = ((pred[:, 0] - 5) / 2.88).view(-1, 1)\n",
    "        print(f'bpe = {bpe}')\n",
    "        size_ratio = torch.argmax(pred[:, 1:], dim=-1).view(-1, 1)\n",
    "        print(f'size_ratio = {size_ratio}')\n",
    "        inputs = torch.concat([bpe, label, size_ratio], dim=-1)\n",
    "\n",
    "        return self.model(inputs).sum(dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4458872e-560e-4e7c-8ec2-a751305c90c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0000, 0.5000, 0.5000, 0.5000, 0.5000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(config['lcm']['data']['mean_bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d473e67b-76b2-41b1-b082-f4ed9f3810e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LTuneIterableDataSet(config, os.path.join(config['io']['data_dir'], 'train-data/workload-parquet'), shuffle=True)\n",
    "train_data = DataLoader(train_dataset, batch_size=2, drop_last=True, num_workers=1)\n",
    "\n",
    "test_dataset = LTuneIterableDataSet(config, os.path.join(config['io']['data_dir'], 'test-data/workload-parquet'), shuffle=False)\n",
    "test_data = DataLoader(train_dataset, batch_size=262114, drop_last=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87aaede4-7fcc-4ca1-95e1-16bc16bcb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassicTuner(config)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = LearnedCostModelLoss(config, model_path='/data/models/level-02-25/best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a5e4736-6f4e-4788-9b3a-c905a600673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(label, features):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(features, temp=0.1, hard=False)\n",
    "    loss = loss_fn(pred, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25d88532-ae54-4635-a254-25bbadf25de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# pbar = tqdm(train_data)\n",
    "# train_len = 0\n",
    "# total_loss = 0\n",
    "# for batch, (label, feature) in enumerate(pbar):\n",
    "#     loss = train_step(label, feature)\n",
    "#     total_loss += loss\n",
    "#     if batch % (100) == 0:\n",
    "#         pbar.set_description(f'loss {loss:e}')\n",
    "\n",
    "# if train_len == 0:\n",
    "#     train_len = batch + 1\n",
    "    \n",
    "# print(total_loss.item() / train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28e196af-2f13-4a21-98d2-bc5a8dc13ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label, feature = next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f50b8803-7a4e-496d-83b9-bc4efd105142",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = tensor([[0.0815, 0.0000, 0.0000, 0.3074, 0.4437, 0.9142, 0.0000, 0.5347, 0.5568,\n",
      "         0.0000, 0.0000, 0.3688, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4142,\n",
      "         0.1886, 0.2064, 0.1307, 0.2196, 0.0505, 0.4013, 0.0000, 0.3229, 0.1442,\n",
      "         0.4675, 0.2901, 0.0000, 0.0000, 0.4141, 0.0000, 0.2329, 0.2210, 0.0000,\n",
      "         0.2363, 0.2924, 0.3720, 0.1871, 0.0983, 0.0000, 0.1649, 0.3223, 0.1346,\n",
      "         0.0000, 0.1666, 0.6351, 0.3379, 0.0026],\n",
      "        [0.0178, 0.0000, 0.0000, 0.4414, 0.0000, 0.1314, 0.0000, 0.2797, 0.4673,\n",
      "         0.0000, 0.0000, 0.2658, 0.0000, 0.0224, 0.0000, 0.0000, 0.0000, 0.2770,\n",
      "         0.1260, 0.1578, 0.1142, 0.1776, 0.0000, 0.1756, 0.0000, 0.1501, 0.2117,\n",
      "         0.1449, 0.0000, 0.0000, 0.0000, 0.2147, 0.0000, 0.1281, 0.1078, 0.0430,\n",
      "         0.0832, 0.4263, 0.1983, 0.1381, 0.2196, 0.0000, 0.0000, 0.1367, 0.0000,\n",
      "         0.0000, 0.0000, 0.6233, 0.3801, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "size_ratio_intermediate = tensor([[0.0815, 0.0000, 0.0000, 0.3074, 0.4437, 0.9142, 0.0000, 0.5347, 0.5568,\n",
      "         0.0000, 0.0000, 0.3688, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4142,\n",
      "         0.1886, 0.2064, 0.1307, 0.2196, 0.0505, 0.4013, 0.0000, 0.3229, 0.1442,\n",
      "         0.4675, 0.2901, 0.0000, 0.0000, 0.4141, 0.0000, 0.2329, 0.2210, 0.0000,\n",
      "         0.2363, 0.2924, 0.3720, 0.1871, 0.0983, 0.0000, 0.1649, 0.3223, 0.1346,\n",
      "         0.0000, 0.1666, 0.6351, 0.3379, 0.0026],\n",
      "        [0.0178, 0.0000, 0.0000, 0.4414, 0.0000, 0.1314, 0.0000, 0.2797, 0.4673,\n",
      "         0.0000, 0.0000, 0.2658, 0.0000, 0.0224, 0.0000, 0.0000, 0.0000, 0.2770,\n",
      "         0.1260, 0.1578, 0.1142, 0.1776, 0.0000, 0.1756, 0.0000, 0.1501, 0.2117,\n",
      "         0.1449, 0.0000, 0.0000, 0.0000, 0.2147, 0.0000, 0.1281, 0.1078, 0.0430,\n",
      "         0.0832, 0.4263, 0.1983, 0.1381, 0.2196, 0.0000, 0.0000, 0.1367, 0.0000,\n",
      "         0.0000, 0.0000, 0.6233, 0.3801, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "t gumbel = tensor([[4.1825e-19, 1.2494e-28, 9.4802e-25, 2.0578e-30, 2.1708e-25, 1.9035e-20,\n",
      "         2.2102e-20, 5.8653e-23, 6.0511e-17, 9.8905e-17, 6.7584e-24, 7.2134e-20,\n",
      "         6.0915e-26, 1.2744e-19, 3.7841e-19, 1.3679e-25, 1.3473e-22, 7.2265e-20,\n",
      "         9.6448e-12, 1.7624e-21, 1.6841e-21, 6.3368e-22, 9.1649e-18, 4.4328e-20,\n",
      "         3.9145e-26, 6.5912e-20, 7.7627e-15, 1.3967e-12, 2.3007e-11, 1.1238e-09,\n",
      "         1.4202e-24, 3.6824e-11, 2.3211e-22, 5.5700e-20, 1.0000e+00, 2.1354e-26,\n",
      "         1.0756e-26, 3.8920e-27, 4.9729e-13, 1.5327e-14, 1.3886e-23, 1.8193e-18,\n",
      "         2.5425e-14, 2.5695e-25, 3.3905e-22, 3.7189e-20, 6.0544e-21, 4.5069e-18,\n",
      "         8.9756e-24],\n",
      "        [1.3630e-14, 2.5190e-19, 6.7134e-25, 5.3612e-27, 6.7026e-12, 3.8695e-24,\n",
      "         1.0343e-12, 8.2580e-22, 6.6054e-26, 2.5128e-24, 2.7464e-20, 3.2281e-28,\n",
      "         1.7983e-18, 2.0894e-25, 3.8247e-18, 8.0432e-22, 4.8198e-19, 1.5552e-27,\n",
      "         1.6750e-13, 3.7183e-28, 3.7944e-20, 1.6697e-30, 6.4991e-25, 2.9166e-21,\n",
      "         1.0000e+00, 4.4526e-12, 6.8347e-23, 2.4591e-21, 2.4165e-07, 2.8538e-19,\n",
      "         8.2366e-25, 1.8470e-21, 2.4593e-20, 5.0571e-20, 8.9817e-24, 1.2474e-18,\n",
      "         3.2703e-25, 8.8165e-26, 7.0691e-28, 1.1212e-25, 1.0146e-11, 9.0487e-19,\n",
      "         4.0227e-18, 3.0234e-19, 6.2517e-20, 1.5159e-25, 2.5914e-26, 9.7858e-26,\n",
      "         3.5364e-22]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 4.1825e-19, 1.2494e-28, 9.4802e-25, 2.0578e-30, 2.1708e-25,\n",
       "         1.9035e-20, 2.2102e-20, 5.8653e-23, 6.0511e-17, 9.8905e-17, 6.7584e-24,\n",
       "         7.2134e-20, 6.0915e-26, 1.2744e-19, 3.7841e-19, 1.3679e-25, 1.3473e-22,\n",
       "         7.2265e-20, 9.6448e-12, 1.7624e-21, 1.6841e-21, 6.3368e-22, 9.1649e-18,\n",
       "         4.4328e-20, 3.9145e-26, 6.5912e-20, 7.7627e-15, 1.3967e-12, 2.3007e-11,\n",
       "         1.1238e-09, 1.4202e-24, 3.6824e-11, 2.3211e-22, 5.5700e-20, 1.0000e+00,\n",
       "         2.1354e-26, 1.0756e-26, 3.8920e-27, 4.9729e-13, 1.5327e-14, 1.3886e-23,\n",
       "         1.8193e-18, 2.5425e-14, 2.5695e-25, 3.3905e-22, 3.7189e-20, 6.0544e-21,\n",
       "         4.5069e-18, 8.9756e-24],\n",
       "        [0.0000e+00, 1.3630e-14, 2.5190e-19, 6.7134e-25, 5.3612e-27, 6.7026e-12,\n",
       "         3.8695e-24, 1.0343e-12, 8.2580e-22, 6.6054e-26, 2.5128e-24, 2.7464e-20,\n",
       "         3.2281e-28, 1.7983e-18, 2.0894e-25, 3.8247e-18, 8.0432e-22, 4.8198e-19,\n",
       "         1.5552e-27, 1.6750e-13, 3.7183e-28, 3.7944e-20, 1.6697e-30, 6.4991e-25,\n",
       "         2.9166e-21, 1.0000e+00, 4.4526e-12, 6.8347e-23, 2.4591e-21, 2.4165e-07,\n",
       "         2.8538e-19, 8.2366e-25, 1.8470e-21, 2.4593e-20, 5.0571e-20, 8.9817e-24,\n",
       "         1.2474e-18, 3.2703e-25, 8.8165e-26, 7.0691e-28, 1.1212e-25, 1.0146e-11,\n",
       "         9.0487e-19, 4.0227e-18, 3.0234e-19, 6.2517e-20, 1.5159e-25, 2.5914e-26,\n",
       "         9.7858e-26, 3.5364e-22]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(feature)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4920532-eb49-4612-ab4a-ff9b1c54df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe = tensor([[-1.7361],\n",
      "        [-1.7361]], grad_fn=<ViewBackward0>)\n",
      "size_ratio = tensor([[34],\n",
      "        [24]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce63c3-2819-4dc3-900a-2bc1b585fdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
