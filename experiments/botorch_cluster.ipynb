{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1daed582-1e72-4f05-b692-3d08b57521fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Optional, Tuple\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from itertools import product\n",
    "import toml\n",
    "\n",
    "from botorch.models import MixedSingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import ExpectedImprovement, UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf_mixed\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f130e4-42e2-444c-9d17-7ca4299557b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from endure.lsm.cost import EndureCost\n",
    "from endure.lsm.types import LSMDesign, System, Policy, Workload, LSMBounds\n",
    "from endure.lcm.data.generator import KHybridGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02462143-188b-4a9a-bde8-ae9fc3fcb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_feature_list(bounds: torch.Tensor) -> List:\n",
    "        lower_t_bound = bounds.size_ratio_range[0]\n",
    "        upper_t_bound = bounds.size_ratio_range[1]\n",
    "        fixed_features_list = []\n",
    "        for t in range(2, upper_t_bound + 1):\n",
    "                param_values = [range(1, upper_t_bound)] * num_k_values\n",
    "                for combination in product(*param_values):\n",
    "                    fixed_feature = {1: t}\n",
    "                    fixed_feature.update(\n",
    "                        {i + 2: combination[i] for i in range(len(combination))}\n",
    "                    )\n",
    "                    fixed_features_list.append(fixed_feature)\n",
    "        return fixed_features_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bd8edb3-d708-4ba1-abab-6d7b76fb70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '/data_comp/train-data/lcm/std/kcost'\n",
    "parquet_files = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('0000.parquet')]\n",
    "df = pd.concat([pd.read_parquet(file) for file in parquet_files], ignore_index=True)\n",
    "df['total_cost'] = df['z0_cost'] + df['z1_cost'] + df['q_cost'] + df['w_cost']\n",
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88a6d1fa-e025-43ad-80dd-f9546e471209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['z0_cost', 'z1_cost', 'q_cost', 'w_cost', 'z0', 'z1', 'q', 'w',\n",
      "       'entry_p_page', 'selec', 'entry_size', 'max_h', 'num_elem', 'h', 'T',\n",
      "       'K_0', 'K_1', 'K_2', 'K_3', 'K_4', 'K_5', 'K_6', 'K_7', 'K_8', 'K_9',\n",
      "       'K_10', 'K_11', 'K_12', 'K_13', 'K_14', 'K_15', 'K_16', 'K_17', 'K_18',\n",
      "       'K_19', 'total_cost'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bf4b1c8-a2a1-4397-9630-11c339d75cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "workload_columns = ['z0', 'z1', 'q', 'w']\n",
    "design_columns = ['h', 'T'] + [f'K_{i}' for i in range(20)]\n",
    "X_workload = df[workload_columns].values\n",
    "\n",
    "X = df[design_columns].values\n",
    "y = df['total_cost'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled = torch.tensor(X_scaled, dtype=torch.float64)\n",
    "y = torch.tensor(y, dtype=torch.float64).unsqueeze(-1)\n",
    "\n",
    "with open(\"endure.toml\") as fid:\n",
    "        config = toml.load(fid)\n",
    "def_bounds = LSMBounds(**config[\"lsm\"][\"bounds\"])\n",
    "cf: EndureCost = EndureCost(def_bounds.max_considered_levels)\n",
    "# num_k_values = config[\"job\"][\"BayesianOptimization\"][\"num_k_values\"]\n",
    "num_k_values = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2790117d-9ff5-452e-80bb-e1f14d9a8ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwesha/endurance/venv_endurance/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 5\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(X_workload)\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8baf4cb1-3b6e-4568-b225-06ea2dd5f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_mixed_gp_model(train_X, train_Y, cat_dims, bounds):\n",
    "    train_Y = (train_Y - train_Y.mean()) / train_Y.std()\n",
    "    gp = MixedSingleTaskGP(\n",
    "        train_X, train_Y, cat_dims=cat_dims,\n",
    "        input_transform=Normalize(d=train_X.shape[1], bounds=bounds),\n",
    "        outcome_transform=Standardize(m=1)\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb62e29a-a51d-4621-a1f8-e3a49c3aef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bounds() -> torch.Tensor:\n",
    "        h_bounds = torch.tensor(\n",
    "            [\n",
    "                def_bounds.bits_per_elem_range[0],\n",
    "                def_bounds.bits_per_elem_range[1],\n",
    "            ],\n",
    "            dtype=torch.float,\n",
    "        )\n",
    "\n",
    "        t_bounds = torch.tensor(def_bounds.size_ratio_range)\n",
    "        policy_bounds = torch.tensor([0, 1])\n",
    "        \n",
    "        lower_limits = [\n",
    "            def_bounds.bits_per_elem_range[0],\n",
    "            def_bounds.size_ratio_range[0],\n",
    "            ] + [1] * num_k_values\n",
    "        upper_limits = [\n",
    "            def_bounds.bits_per_elem_range[1],\n",
    "            def_bounds.size_ratio_range[1],\n",
    "            ] + [def_bounds.size_ratio_range[1] - 1] * num_k_values\n",
    "        new_bounds_list = [lower_limits, upper_limits]\n",
    "        bounds = torch.tensor(new_bounds_list, dtype=torch.float64)\n",
    "        return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e7e9160-45cb-41c0-a578-b8b5cd3e53d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwesha/endurance/venv_endurance/lib/python3.10/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/home/anwesha/endurance/venv_endurance/lib/python3.10/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/home/anwesha/endurance/venv_endurance/lib/python3.10/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/home/anwesha/endurance/venv_endurance/lib/python3.10/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/home/anwesha/endurance/venv_endurance/lib/python3.10/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    }
   ],
   "source": [
    "gp_models = []\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    cluster_indices = np.where(labels == i)[0]\n",
    "    X_cluster_design = X_scaled[cluster_indices]\n",
    "    y_cluster = y[cluster_indices]\n",
    "    best_y = y_cluster.min().item()\n",
    "    cat_dims = list(range(1, def_bounds.max_considered_levels + 2))\n",
    "    bounds = gen_bounds()\n",
    "    gp_model = def_mixed_gp_model(X_cluster_design, y_cluster, cat_dims, bounds)\n",
    "    gp_models.append(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08982890-92ba-45c7-ab13-4b330cbe31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_design_for_workload(workload, centroids, gp_models, bounds):\n",
    "    workload_array = np.array([workload.z0, workload.z1, workload.q, workload.w])\n",
    "    distances = np.linalg.norm(centroids - workload_array, axis=1)\n",
    "    closest_cluster = np.argmin(distances)\n",
    "    gp_model = gp_models[closest_cluster]\n",
    "    workload_tensor = torch.tensor(workload_array, dtype=torch.float32).unsqueeze(0)\n",
    "    gp_model.eval()\n",
    "    acqf = ExpectedImprovement(model=gp_model, best_f=best_y, maximize=False)\n",
    "    fixed_feature_list = initialize_feature_list(def_bounds) \n",
    "    with torch.no_grad():\n",
    "        candidate, acq_value = optimize_acqf_mixed(\n",
    "            acq_function=acqf,\n",
    "            bounds=bounds,\n",
    "            q=1,\n",
    "            num_restarts=5,\n",
    "            raw_samples=20,\n",
    "            fixed_features_list=[]\n",
    "        )\n",
    "    \n",
    "    design = candidate.squeeze().numpy()\n",
    "    return design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2787f-25f7-44cd-b783-0f21ca3f0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_designs(generator, bounds, centroids, gp_models):\n",
    "    designs = []\n",
    "    for _ in range(5):\n",
    "        z0, z1, q, w = generator._sample_workload(4)\n",
    "        workload = Workload(z0=z0, z1=z1, q=q, w=w)\n",
    "        new_design = suggest_design_for_workload(workload, centroids, gp_models, bounds)\n",
    "        designs.append(new_design)\n",
    "        print(new_design)\n",
    "    return designs\n",
    "\n",
    "generator = KHybridGenerator(def_bounds)\n",
    "bounds = torch.tensor([\n",
    "    [def_bounds.bits_per_elem_range[0], def_bounds.size_ratio_range[0]] + [1] * num_k_values,\n",
    "    [def_bounds.bits_per_elem_range[1], def_bounds.size_ratio_range[1]] + [def_bounds.size_ratio_range[1] - 1] * num_k_values\n",
    "], dtype=torch.float32).T\n",
    "designs = generate_designs(generator, bounds, centroids, gp_models)\n",
    "\n",
    "check_identical_designs(designs, idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7dbca4-f20b-4596-b82e-c1a87b73770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = KHybridGenerator(def_bounds)\n",
    "bounds = torch.tensor([\n",
    "    [def_bounds.bits_per_elem_range[0], def_bounds.size_ratio_range[0]] + [1] * num_k_values,\n",
    "    [def_bounds.bits_per_elem_range[1], def_bounds.size_ratio_range[1]] + [def_bounds.size_ratio_range[1] - 1] * num_k_values\n",
    "designs = generate_designs(generator, bounds, centroids, gp_models)\n",
    "\n",
    "# Check for identical designs (assuming the function check_identical_designs is defined elsewhere)\n",
    "check_identical_designs(designs, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e252ed7-8d71-4b4a-89b2-68356bdd3596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff4e2f-28f4-4cf0-aafa-921ef1c7d823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
