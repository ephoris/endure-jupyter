{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb165fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import pandas as pd\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s]: %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8634fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KCostDataSet(Dataset):\n",
    "    def __init__(self, transform=None, target_transform=None):\n",
    "        self.df = pd.read_csv('/Users/ndhuynh/sandbox/data/cost_surface_k.csv')\n",
    "        data = self.df['K'].map(lambda x: list(map(int, x[1:-1].split())))\n",
    "        Ks = pd.DataFrame(data.to_list()).add_prefix('K_').fillna(0)\n",
    "        self.df = pd.concat([self.df, Ks], axis=1)\n",
    "        \n",
    "        max_levels = self.df.query('T == 2')['K'].apply(lambda x: len(x[1:-1].split())).max()\n",
    "        input_cols = ['h', 'T', 'z0', 'z1', 'q', 'w'] + [f'K_{i}' for i in range(max_levels)]\n",
    "        output_cols = ['new_cost']\n",
    "        \n",
    "        mean = self.df[input_cols].mean()\n",
    "        std = self.df[input_cols].std()\n",
    "        std[std == 0] = 1\n",
    "        self.df[input_cols] = (self.df[input_cols] - mean) / std\n",
    "        \n",
    "        self.inputs = torch.from_numpy(self.df[input_cols].values).float()\n",
    "        self.outputs = torch.from_numpy(self.df[output_cols].values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.inputs[idx]\n",
    "        label = self.outputs[idx]\n",
    "\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20a169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KCostNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KCostNeuralNet, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(21, 21),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(21, 21),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(21, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear_relu_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5870604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = KCostDataSet()\n",
    "val_len = len(data) - int(len(data) * 0.05)\n",
    "train_len = len(data) - val_len\n",
    "train, val = torch.utils.data.random_split(data, [train_len, val_len])\n",
    "train = DataLoader(train, batch_size=1024, num_workers=0, shuffle=True)\n",
    "val = DataLoader(val, batch_size=1024, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54d517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "model = KCostNeuralNet()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a8ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % (500) == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            log.info(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    log.info(f'validation loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e6bf455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:35:49]: Epoch 1\n",
      "-------------------------------\n",
      "[16:35:49]: loss: 527.707825  [    0/1217195]\n",
      "[16:35:50]: loss: 19.901567  [512000/1217195]\n",
      "[16:35:51]: loss: 5.366539  [1024000/1217195]\n",
      "[16:36:55]: validation loss: 5.128123\n",
      "\n",
      "[16:36:55]: Epoch 2\n",
      "-------------------------------\n",
      "[16:36:56]: loss: 5.365809  [    0/1217195]\n",
      "[16:36:58]: loss: 2.816974  [512000/1217195]\n",
      "[16:37:00]: loss: 1.969640  [1024000/1217195]\n",
      "[16:38:39]: validation loss: 1.673957\n",
      "\n",
      "[16:38:39]: Epoch 3\n",
      "-------------------------------\n",
      "[16:38:39]: loss: 1.891552  [    0/1217195]\n",
      "[16:38:41]: loss: 1.569899  [512000/1217195]\n",
      "[16:38:43]: loss: 1.314659  [1024000/1217195]\n",
      "[16:40:23]: validation loss: 1.173841\n",
      "\n",
      "[16:40:23]: Epoch 4\n",
      "-------------------------------\n",
      "[16:40:23]: loss: 0.948044  [    0/1217195]\n",
      "[16:40:25]: loss: 1.041244  [512000/1217195]\n",
      "[16:40:28]: loss: 0.819875  [1024000/1217195]\n",
      "[16:42:06]: validation loss: 0.920453\n",
      "\n",
      "[16:42:06]: Epoch 5\n",
      "-------------------------------\n",
      "[16:42:06]: loss: 0.875225  [    0/1217195]\n",
      "[16:42:09]: loss: 0.717784  [512000/1217195]\n",
      "[16:42:11]: loss: 0.569655  [1024000/1217195]\n",
      "[16:43:50]: validation loss: 0.755540\n",
      "\n",
      "[16:43:50]: Epoch 6\n",
      "-------------------------------\n",
      "[16:43:50]: loss: 0.850263  [    0/1217195]\n",
      "[16:43:52]: loss: 0.580589  [512000/1217195]\n",
      "[16:43:55]: loss: 0.638023  [1024000/1217195]\n",
      "[16:45:33]: validation loss: 0.663545\n",
      "\n",
      "[16:45:33]: Epoch 7\n",
      "-------------------------------\n",
      "[16:45:33]: loss: 0.544007  [    0/1217195]\n",
      "[16:45:36]: loss: 0.521035  [512000/1217195]\n",
      "[16:45:38]: loss: 0.620216  [1024000/1217195]\n",
      "[16:47:17]: validation loss: 0.582260\n",
      "\n",
      "[16:47:17]: Epoch 8\n",
      "-------------------------------\n",
      "[16:47:17]: loss: 0.840621  [    0/1217195]\n",
      "[16:47:19]: loss: 0.498629  [512000/1217195]\n",
      "[16:47:22]: loss: 0.484148  [1024000/1217195]\n",
      "[16:49:00]: validation loss: 0.538153\n",
      "\n",
      "[16:49:00]: Epoch 9\n",
      "-------------------------------\n",
      "[16:49:00]: loss: 0.489410  [    0/1217195]\n",
      "[16:49:02]: loss: 0.401883  [512000/1217195]\n",
      "[16:49:04]: loss: 0.384119  [1024000/1217195]\n",
      "[16:50:43]: validation loss: 0.495513\n",
      "\n",
      "[16:50:43]: Epoch 10\n",
      "-------------------------------\n",
      "[16:50:43]: loss: 0.455598  [    0/1217195]\n",
      "[16:50:45]: loss: 0.423765  [512000/1217195]\n",
      "[16:50:48]: loss: 0.456874  [1024000/1217195]\n",
      "[16:52:26]: validation loss: 0.477143\n",
      "\n",
      "[16:52:26]: Epoch 11\n",
      "-------------------------------\n",
      "[16:52:26]: loss: 0.651315  [    0/1217195]\n",
      "[16:52:29]: loss: 0.782363  [512000/1217195]\n",
      "[16:52:31]: loss: 0.342698  [1024000/1217195]\n",
      "[16:54:09]: validation loss: 0.426476\n",
      "\n",
      "[16:54:09]: Epoch 12\n",
      "-------------------------------\n",
      "[16:54:09]: loss: 0.544864  [    0/1217195]\n",
      "[16:54:12]: loss: 0.603829  [512000/1217195]\n",
      "[16:54:14]: loss: 0.433321  [1024000/1217195]\n",
      "[16:55:52]: validation loss: 0.394189\n",
      "\n",
      "[16:55:52]: Epoch 13\n",
      "-------------------------------\n",
      "[16:55:52]: loss: 0.432406  [    0/1217195]\n",
      "[16:55:55]: loss: 0.316048  [512000/1217195]\n",
      "[16:55:57]: loss: 0.375814  [1024000/1217195]\n",
      "[16:57:35]: validation loss: 0.380778\n",
      "\n",
      "[16:57:35]: Epoch 14\n",
      "-------------------------------\n",
      "[16:57:35]: loss: 0.295383  [    0/1217195]\n",
      "[16:57:37]: loss: 0.378619  [512000/1217195]\n",
      "[16:57:40]: loss: 0.360303  [1024000/1217195]\n",
      "[16:59:18]: validation loss: 0.352574\n",
      "\n",
      "[16:59:18]: Epoch 15\n",
      "-------------------------------\n",
      "[16:59:18]: loss: 0.518436  [    0/1217195]\n",
      "[16:59:20]: loss: 0.404165  [512000/1217195]\n",
      "[16:59:22]: loss: 0.393456  [1024000/1217195]\n",
      "[17:01:01]: validation loss: 0.326355\n",
      "\n",
      "[17:01:01]: Epoch 16\n",
      "-------------------------------\n",
      "[17:01:01]: loss: 0.338256  [    0/1217195]\n",
      "[17:01:03]: loss: 0.287896  [512000/1217195]\n",
      "[17:01:06]: loss: 0.335510  [1024000/1217195]\n",
      "[17:02:44]: validation loss: 0.312278\n",
      "\n",
      "[17:02:44]: Epoch 17\n",
      "-------------------------------\n",
      "[17:02:44]: loss: 0.314656  [    0/1217195]\n",
      "[17:02:46]: loss: 0.250095  [512000/1217195]\n",
      "[17:02:49]: loss: 0.268139  [1024000/1217195]\n",
      "[17:04:27]: validation loss: 0.299658\n",
      "\n",
      "[17:04:27]: Epoch 18\n",
      "-------------------------------\n",
      "[17:04:27]: loss: 0.256021  [    0/1217195]\n",
      "[17:04:29]: loss: 0.218112  [512000/1217195]\n",
      "[17:04:32]: loss: 0.302287  [1024000/1217195]\n",
      "[17:06:10]: validation loss: 0.284664\n",
      "\n",
      "[17:06:10]: Epoch 19\n",
      "-------------------------------\n",
      "[17:06:10]: loss: 0.256812  [    0/1217195]\n",
      "[17:06:12]: loss: 0.196867  [512000/1217195]\n",
      "[17:06:15]: loss: 0.230016  [1024000/1217195]\n",
      "[17:07:53]: validation loss: 0.277514\n",
      "\n",
      "[17:07:53]: Epoch 20\n",
      "-------------------------------\n",
      "[17:07:53]: loss: 0.175931  [    0/1217195]\n",
      "[17:07:56]: loss: 0.314318  [512000/1217195]\n",
      "[17:07:58]: loss: 0.240499  [1024000/1217195]\n",
      "[17:09:37]: validation loss: 0.270138\n",
      "\n",
      "[17:09:37]: Epoch 21\n",
      "-------------------------------\n",
      "[17:09:37]: loss: 0.318664  [    0/1217195]\n",
      "[17:09:39]: loss: 0.153695  [512000/1217195]\n",
      "[17:09:41]: loss: 0.258654  [1024000/1217195]\n",
      "[17:11:20]: validation loss: 0.260726\n",
      "\n",
      "[17:11:20]: Epoch 22\n",
      "-------------------------------\n",
      "[17:11:20]: loss: 0.259458  [    0/1217195]\n",
      "[17:11:22]: loss: 0.334170  [512000/1217195]\n",
      "[17:11:25]: loss: 0.264949  [1024000/1217195]\n",
      "[17:13:03]: validation loss: 0.255810\n",
      "\n",
      "[17:13:03]: Epoch 23\n",
      "-------------------------------\n",
      "[17:13:03]: loss: 0.191316  [    0/1217195]\n",
      "[17:13:05]: loss: 0.175167  [512000/1217195]\n",
      "[17:13:08]: loss: 0.289088  [1024000/1217195]\n",
      "[17:14:46]: validation loss: 0.249052\n",
      "\n",
      "[17:14:46]: Epoch 24\n",
      "-------------------------------\n",
      "[17:14:46]: loss: 0.273293  [    0/1217195]\n",
      "[17:14:49]: loss: 0.219621  [512000/1217195]\n",
      "[17:14:51]: loss: 0.247881  [1024000/1217195]\n",
      "[17:16:30]: validation loss: 0.249316\n",
      "\n",
      "[17:16:30]: Epoch 25\n",
      "-------------------------------\n",
      "[17:16:30]: loss: 0.395573  [    0/1217195]\n",
      "[17:16:32]: loss: 0.237053  [512000/1217195]\n",
      "[17:16:35]: loss: 0.164908  [1024000/1217195]\n",
      "[17:18:13]: validation loss: 0.231951\n",
      "\n",
      "[17:18:13]: Epoch 26\n",
      "-------------------------------\n",
      "[17:18:13]: loss: 0.243678  [    0/1217195]\n",
      "[17:18:15]: loss: 0.293224  [512000/1217195]\n",
      "[17:18:17]: loss: 0.242601  [1024000/1217195]\n",
      "[17:19:56]: validation loss: 0.227462\n",
      "\n",
      "[17:19:56]: Epoch 27\n",
      "-------------------------------\n",
      "[17:19:56]: loss: 0.307644  [    0/1217195]\n",
      "[17:19:58]: loss: 0.322545  [512000/1217195]\n",
      "[17:20:00]: loss: 0.253193  [1024000/1217195]\n",
      "[17:21:39]: validation loss: 0.221250\n",
      "\n",
      "[17:21:39]: Epoch 28\n",
      "-------------------------------\n",
      "[17:21:39]: loss: 0.176310  [    0/1217195]\n",
      "[17:21:41]: loss: 0.158555  [512000/1217195]\n",
      "[17:21:44]: loss: 0.154176  [1024000/1217195]\n",
      "[17:23:22]: validation loss: 0.220484\n",
      "\n",
      "[17:23:22]: Epoch 29\n",
      "-------------------------------\n",
      "[17:23:22]: loss: 0.207651  [    0/1217195]\n",
      "[17:23:24]: loss: 0.159957  [512000/1217195]\n",
      "[17:23:27]: loss: 0.275205  [1024000/1217195]\n",
      "[17:25:05]: validation loss: 0.225935\n",
      "\n",
      "[17:25:05]: Epoch 30\n",
      "-------------------------------\n",
      "[17:25:05]: loss: 0.162687  [    0/1217195]\n",
      "[17:25:08]: loss: 0.171125  [512000/1217195]\n",
      "[17:25:10]: loss: 0.230094  [1024000/1217195]\n",
      "[17:26:48]: validation loss: 0.216568\n",
      "\n",
      "[17:26:48]: Epoch 31\n",
      "-------------------------------\n",
      "[17:26:48]: loss: 0.148704  [    0/1217195]\n",
      "[17:26:51]: loss: 0.169493  [512000/1217195]\n",
      "[17:26:53]: loss: 0.152550  [1024000/1217195]\n",
      "[17:28:32]: validation loss: 0.210314\n",
      "\n",
      "[17:28:32]: Epoch 32\n",
      "-------------------------------\n",
      "[17:28:32]: loss: 0.327435  [    0/1217195]\n",
      "[17:28:34]: loss: 0.168598  [512000/1217195]\n",
      "[17:28:36]: loss: 0.184430  [1024000/1217195]\n",
      "[17:30:15]: validation loss: 0.209715\n",
      "\n",
      "[17:30:15]: Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 32\n",
    "for t in range(epochs):\n",
    "    log.info(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train, model, loss_fn, optimizer)\n",
    "    test_loop(val, model, loss_fn)\n",
    "log.info(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf7cd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.5769e+00, -3.3111e+00, -2.0781e-14, -2.2411e-14, -2.4040e-14,\n",
       "         -2.5874e-14, -2.3647e+00, -1.6430e+00, -9.3732e-01,  1.1826e+00,\n",
       "          9.9400e+00,  2.7035e+01,  5.7396e+01,  8.6080e+01,  1.1828e+02,\n",
       "          6.3374e+01, -1.0787e-02, -7.9190e-03, -5.7924e-03, -4.2199e-03,\n",
       "         -3.0614e-03]),\n",
       " tensor([8.1739]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data[1]\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bee7f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.5977], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb04b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
