{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17448f69-e742-4c48-8d7e-e9d2c3891d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import toml\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torcharrow\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchdata import datapipes as DataPipe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as SciOpt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(os.path.join(sys.path[0], '../..'))\n",
    "\n",
    "from data.io import Reader\n",
    "from lsm.lsmtype import Policy\n",
    "from jobs.train import TrainJob\n",
    "from model.trainer import Trainer\n",
    "import lsm.cost as CostFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a2e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Reader.read_config('../../endure.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3df313d-9e06-4aa5-9f4a-cd9185025602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndureQDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, config, fnames):\n",
    "        self._config = config\n",
    "        self._mean = np.array(self._config['train']['mean_bias'], np.float32)\n",
    "        self._std = np.array(self._config['train']['std_bias'], np.float32)\n",
    "        \n",
    "        self._df = self._load_data(fnames)\n",
    "        self._label_cols = ['z0_cost', 'z1_cost', 'q_cost', 'w_cost']\n",
    "        self._input_cols = ['h', 'z0', 'z1', 'q', 'w', 'T', 'Q']\n",
    "        \n",
    "        self.inputs = torch.from_numpy(self._df[self._input_cols].values).float()\n",
    "        self.labels = torch.from_numpy(self._df[self._label_cols].values).float()\n",
    "    \n",
    "    def _load_data(self, fnames):\n",
    "        df = []\n",
    "        for fname in fnames:\n",
    "            df.append(pd.read_csv(fname))\n",
    "        df = pd.concat(df)\n",
    "        return self._process_df(df)\n",
    "    \n",
    "    def _process_df(self, df):\n",
    "        df[['h', 'z0', 'z1', 'q', 'w']] -= self._mean\n",
    "        df[['h', 'z0', 'z1', 'q', 'w']] /= self._std\n",
    "        df['T'] = df['T'] - self._config['lsm']['size_ratio']['min']\n",
    "        df['Q'] = df['Q'] - (self._config['lsm']['size_ratio']['min'] - 1)\n",
    "        return df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.labels[idx], self.inputs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55fc986",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/train-data/qcost/qcost-0036.csv',\n",
       " '/data/train-data/qcost/qcost-0032.csv',\n",
       " '/data/train-data/qcost/qcost-0012.csv',\n",
       " '/data/train-data/qcost/qcost-0048.csv',\n",
       " '/data/train-data/qcost/qcost-0020.csv',\n",
       " '/data/train-data/qcost/qcost-0052.csv',\n",
       " '/data/train-data/qcost/qcost-0060.csv',\n",
       " '/data/train-data/qcost/qcost-0004.csv',\n",
       " '/data/train-data/qcost/qcost-0028.csv',\n",
       " '/data/train-data/qcost/qcost-0040.csv',\n",
       " '/data/train-data/qcost/qcost-0024.csv',\n",
       " '/data/train-data/qcost/qcost-0000.csv',\n",
       " '/data/train-data/qcost/qcost-0008.csv',\n",
       " '/data/train-data/qcost/qcost-0056.csv',\n",
       " '/data/train-data/qcost/qcost-0016.csv',\n",
       " '/data/train-data/qcost/qcost-0044.csv',\n",
       " '/data/train-data/qcost/qcost-0037.csv',\n",
       " '/data/train-data/qcost/qcost-0049.csv',\n",
       " '/data/train-data/qcost/qcost-0061.csv',\n",
       " '/data/train-data/qcost/qcost-0053.csv',\n",
       " '/data/train-data/qcost/qcost-0021.csv',\n",
       " '/data/train-data/qcost/qcost-0029.csv',\n",
       " '/data/train-data/qcost/qcost-0005.csv',\n",
       " '/data/train-data/qcost/qcost-0041.csv',\n",
       " '/data/train-data/qcost/qcost-0001.csv',\n",
       " '/data/train-data/qcost/qcost-0025.csv',\n",
       " '/data/train-data/qcost/qcost-0009.csv',\n",
       " '/data/train-data/qcost/qcost-0017.csv',\n",
       " '/data/train-data/qcost/qcost-0013.csv',\n",
       " '/data/train-data/qcost/qcost-0045.csv',\n",
       " '/data/train-data/qcost/qcost-0033.csv',\n",
       " '/data/train-data/qcost/qcost-0057.csv',\n",
       " '/data/train-data/qcost/qcost-0038.csv',\n",
       " '/data/train-data/qcost/qcost-0022.csv',\n",
       " '/data/train-data/qcost/qcost-0054.csv',\n",
       " '/data/train-data/qcost/qcost-0006.csv',\n",
       " '/data/train-data/qcost/qcost-0018.csv',\n",
       " '/data/train-data/qcost/qcost-0062.csv',\n",
       " '/data/train-data/qcost/qcost-0026.csv',\n",
       " '/data/train-data/qcost/qcost-0050.csv',\n",
       " '/data/train-data/qcost/qcost-0002.csv',\n",
       " '/data/train-data/qcost/qcost-0046.csv',\n",
       " '/data/train-data/qcost/qcost-0030.csv',\n",
       " '/data/train-data/qcost/qcost-0010.csv',\n",
       " '/data/train-data/qcost/qcost-0034.csv',\n",
       " '/data/train-data/qcost/qcost-0042.csv',\n",
       " '/data/train-data/qcost/qcost-0014.csv',\n",
       " '/data/train-data/qcost/qcost-0058.csv',\n",
       " '/data/train-data/qcost/qcost-0023.csv',\n",
       " '/data/train-data/qcost/qcost-0019.csv',\n",
       " '/data/train-data/qcost/qcost-0007.csv',\n",
       " '/data/train-data/qcost/qcost-0027.csv',\n",
       " '/data/train-data/qcost/qcost-0003.csv',\n",
       " '/data/train-data/qcost/qcost-0047.csv',\n",
       " '/data/train-data/qcost/qcost-0039.csv',\n",
       " '/data/train-data/qcost/qcost-0051.csv',\n",
       " '/data/train-data/qcost/qcost-0011.csv',\n",
       " '/data/train-data/qcost/qcost-0063.csv',\n",
       " '/data/train-data/qcost/qcost-0055.csv',\n",
       " '/data/train-data/qcost/qcost-0031.csv',\n",
       " '/data/train-data/qcost/qcost-0035.csv',\n",
       " '/data/train-data/qcost/qcost-0043.csv',\n",
       " '/data/train-data/qcost/qcost-0059.csv',\n",
       " '/data/train-data/qcost/qcost-0015.csv',\n",
       " '/data/train-data/qcost/qcost-0064.csv',\n",
       " '/data/train-data/qcost/qcost-0068.csv',\n",
       " '/data/train-data/qcost/qcost-0072.csv',\n",
       " '/data/train-data/qcost/qcost-0076.csv',\n",
       " '/data/train-data/qcost/qcost-0080.csv',\n",
       " '/data/train-data/qcost/qcost-0084.csv',\n",
       " '/data/train-data/qcost/qcost-0088.csv',\n",
       " '/data/train-data/qcost/qcost-0092.csv',\n",
       " '/data/train-data/qcost/qcost-0096.csv',\n",
       " '/data/train-data/qcost/qcost-0100.csv',\n",
       " '/data/train-data/qcost/qcost-0104.csv',\n",
       " '/data/train-data/qcost/qcost-0108.csv',\n",
       " '/data/train-data/qcost/qcost-0112.csv',\n",
       " '/data/train-data/qcost/qcost-0116.csv',\n",
       " '/data/train-data/qcost/qcost-0120.csv',\n",
       " '/data/train-data/qcost/qcost-0124.csv',\n",
       " '/data/train-data/qcost/qcost-0065.csv',\n",
       " '/data/train-data/qcost/qcost-0069.csv',\n",
       " '/data/train-data/qcost/qcost-0077.csv',\n",
       " '/data/train-data/qcost/qcost-0073.csv',\n",
       " '/data/train-data/qcost/qcost-0081.csv',\n",
       " '/data/train-data/qcost/qcost-0085.csv',\n",
       " '/data/train-data/qcost/qcost-0089.csv',\n",
       " '/data/train-data/qcost/qcost-0093.csv',\n",
       " '/data/train-data/qcost/qcost-0101.csv',\n",
       " '/data/train-data/qcost/qcost-0097.csv',\n",
       " '/data/train-data/qcost/qcost-0105.csv',\n",
       " '/data/train-data/qcost/qcost-0109.csv',\n",
       " '/data/train-data/qcost/qcost-0113.csv',\n",
       " '/data/train-data/qcost/qcost-0117.csv',\n",
       " '/data/train-data/qcost/qcost-0121.csv',\n",
       " '/data/train-data/qcost/qcost-0125.csv',\n",
       " '/data/train-data/qcost/qcost-0066.csv',\n",
       " '/data/train-data/qcost/qcost-0070.csv',\n",
       " '/data/train-data/qcost/qcost-0078.csv',\n",
       " '/data/train-data/qcost/qcost-0074.csv',\n",
       " '/data/train-data/qcost/qcost-0082.csv',\n",
       " '/data/train-data/qcost/qcost-0086.csv',\n",
       " '/data/train-data/qcost/qcost-0090.csv',\n",
       " '/data/train-data/qcost/qcost-0094.csv',\n",
       " '/data/train-data/qcost/qcost-0102.csv',\n",
       " '/data/train-data/qcost/qcost-0106.csv',\n",
       " '/data/train-data/qcost/qcost-0098.csv',\n",
       " '/data/train-data/qcost/qcost-0110.csv',\n",
       " '/data/train-data/qcost/qcost-0114.csv',\n",
       " '/data/train-data/qcost/qcost-0118.csv',\n",
       " '/data/train-data/qcost/qcost-0122.csv',\n",
       " '/data/train-data/qcost/qcost-0126.csv',\n",
       " '/data/train-data/qcost/qcost-0067.csv',\n",
       " '/data/train-data/qcost/qcost-0071.csv',\n",
       " '/data/train-data/qcost/qcost-0079.csv',\n",
       " '/data/train-data/qcost/qcost-0075.csv',\n",
       " '/data/train-data/qcost/qcost-0083.csv',\n",
       " '/data/train-data/qcost/qcost-0087.csv',\n",
       " '/data/train-data/qcost/qcost-0091.csv',\n",
       " '/data/train-data/qcost/qcost-0095.csv',\n",
       " '/data/train-data/qcost/qcost-0103.csv',\n",
       " '/data/train-data/qcost/qcost-0107.csv',\n",
       " '/data/train-data/qcost/qcost-0099.csv',\n",
       " '/data/train-data/qcost/qcost-0111.csv',\n",
       " '/data/train-data/qcost/qcost-0115.csv',\n",
       " '/data/train-data/qcost/qcost-0119.csv',\n",
       " '/data/train-data/qcost/qcost-0123.csv',\n",
       " '/data/train-data/qcost/qcost-0127.csv',\n",
       " '/data/train-data/qcost/qcost-0128.csv',\n",
       " '/data/train-data/qcost/qcost-0132.csv',\n",
       " '/data/train-data/qcost/qcost-0136.csv',\n",
       " '/data/train-data/qcost/qcost-0140.csv',\n",
       " '/data/train-data/qcost/qcost-0144.csv',\n",
       " '/data/train-data/qcost/qcost-0148.csv',\n",
       " '/data/train-data/qcost/qcost-0152.csv',\n",
       " '/data/train-data/qcost/qcost-0156.csv',\n",
       " '/data/train-data/qcost/qcost-0160.csv',\n",
       " '/data/train-data/qcost/qcost-0164.csv',\n",
       " '/data/train-data/qcost/qcost-0168.csv',\n",
       " '/data/train-data/qcost/qcost-0172.csv',\n",
       " '/data/train-data/qcost/qcost-0176.csv',\n",
       " '/data/train-data/qcost/qcost-0180.csv',\n",
       " '/data/train-data/qcost/qcost-0184.csv',\n",
       " '/data/train-data/qcost/qcost-0188.csv',\n",
       " '/data/train-data/qcost/qcost-0129.csv',\n",
       " '/data/train-data/qcost/qcost-0133.csv',\n",
       " '/data/train-data/qcost/qcost-0137.csv',\n",
       " '/data/train-data/qcost/qcost-0145.csv',\n",
       " '/data/train-data/qcost/qcost-0141.csv',\n",
       " '/data/train-data/qcost/qcost-0149.csv',\n",
       " '/data/train-data/qcost/qcost-0153.csv',\n",
       " '/data/train-data/qcost/qcost-0157.csv',\n",
       " '/data/train-data/qcost/qcost-0161.csv',\n",
       " '/data/train-data/qcost/qcost-0165.csv',\n",
       " '/data/train-data/qcost/qcost-0169.csv',\n",
       " '/data/train-data/qcost/qcost-0173.csv',\n",
       " '/data/train-data/qcost/qcost-0177.csv',\n",
       " '/data/train-data/qcost/qcost-0181.csv',\n",
       " '/data/train-data/qcost/qcost-0185.csv',\n",
       " '/data/train-data/qcost/qcost-0189.csv',\n",
       " '/data/train-data/qcost/qcost-0130.csv',\n",
       " '/data/train-data/qcost/qcost-0134.csv',\n",
       " '/data/train-data/qcost/qcost-0138.csv',\n",
       " '/data/train-data/qcost/qcost-0150.csv',\n",
       " '/data/train-data/qcost/qcost-0146.csv',\n",
       " '/data/train-data/qcost/qcost-0154.csv',\n",
       " '/data/train-data/qcost/qcost-0142.csv',\n",
       " '/data/train-data/qcost/qcost-0158.csv',\n",
       " '/data/train-data/qcost/qcost-0162.csv',\n",
       " '/data/train-data/qcost/qcost-0166.csv',\n",
       " '/data/train-data/qcost/qcost-0170.csv',\n",
       " '/data/train-data/qcost/qcost-0174.csv',\n",
       " '/data/train-data/qcost/qcost-0178.csv',\n",
       " '/data/train-data/qcost/qcost-0182.csv',\n",
       " '/data/train-data/qcost/qcost-0186.csv',\n",
       " '/data/train-data/qcost/qcost-0190.csv',\n",
       " '/data/train-data/qcost/qcost-0131.csv',\n",
       " '/data/train-data/qcost/qcost-0135.csv',\n",
       " '/data/train-data/qcost/qcost-0139.csv',\n",
       " '/data/train-data/qcost/qcost-0151.csv',\n",
       " '/data/train-data/qcost/qcost-0155.csv',\n",
       " '/data/train-data/qcost/qcost-0147.csv',\n",
       " '/data/train-data/qcost/qcost-0143.csv',\n",
       " '/data/train-data/qcost/qcost-0159.csv',\n",
       " '/data/train-data/qcost/qcost-0163.csv',\n",
       " '/data/train-data/qcost/qcost-0167.csv',\n",
       " '/data/train-data/qcost/qcost-0171.csv',\n",
       " '/data/train-data/qcost/qcost-0175.csv',\n",
       " '/data/train-data/qcost/qcost-0179.csv',\n",
       " '/data/train-data/qcost/qcost-0183.csv',\n",
       " '/data/train-data/qcost/qcost-0187.csv',\n",
       " '/data/train-data/qcost/qcost-0192.csv',\n",
       " '/data/train-data/qcost/qcost-0196.csv',\n",
       " '/data/train-data/qcost/qcost-0200.csv',\n",
       " '/data/train-data/qcost/qcost-0204.csv',\n",
       " '/data/train-data/qcost/qcost-0208.csv',\n",
       " '/data/train-data/qcost/qcost-0212.csv',\n",
       " '/data/train-data/qcost/qcost-0216.csv',\n",
       " '/data/train-data/qcost/qcost-0220.csv',\n",
       " '/data/train-data/qcost/qcost-0224.csv',\n",
       " '/data/train-data/qcost/qcost-0228.csv',\n",
       " '/data/train-data/qcost/qcost-0232.csv',\n",
       " '/data/train-data/qcost/qcost-0191.csv',\n",
       " '/data/train-data/qcost/qcost-0236.csv',\n",
       " '/data/train-data/qcost/qcost-0240.csv',\n",
       " '/data/train-data/qcost/qcost-0244.csv',\n",
       " '/data/train-data/qcost/qcost-0248.csv',\n",
       " '/data/train-data/qcost/qcost-0193.csv',\n",
       " '/data/train-data/qcost/qcost-0197.csv',\n",
       " '/data/train-data/qcost/qcost-0201.csv',\n",
       " '/data/train-data/qcost/qcost-0205.csv',\n",
       " '/data/train-data/qcost/qcost-0209.csv',\n",
       " '/data/train-data/qcost/qcost-0221.csv',\n",
       " '/data/train-data/qcost/qcost-0213.csv',\n",
       " '/data/train-data/qcost/qcost-0217.csv',\n",
       " '/data/train-data/qcost/qcost-0225.csv',\n",
       " '/data/train-data/qcost/qcost-0229.csv',\n",
       " '/data/train-data/qcost/qcost-0233.csv',\n",
       " '/data/train-data/qcost/qcost-0241.csv',\n",
       " '/data/train-data/qcost/qcost-0237.csv',\n",
       " '/data/train-data/qcost/qcost-0252.csv',\n",
       " '/data/train-data/qcost/qcost-0245.csv',\n",
       " '/data/train-data/qcost/qcost-0249.csv',\n",
       " '/data/train-data/qcost/qcost-0194.csv',\n",
       " '/data/train-data/qcost/qcost-0198.csv',\n",
       " '/data/train-data/qcost/qcost-0222.csv',\n",
       " '/data/train-data/qcost/qcost-0202.csv',\n",
       " '/data/train-data/qcost/qcost-0210.csv',\n",
       " '/data/train-data/qcost/qcost-0206.csv',\n",
       " '/data/train-data/qcost/qcost-0226.csv',\n",
       " '/data/train-data/qcost/qcost-0214.csv',\n",
       " '/data/train-data/qcost/qcost-0230.csv',\n",
       " '/data/train-data/qcost/qcost-0218.csv',\n",
       " '/data/train-data/qcost/qcost-0234.csv',\n",
       " '/data/train-data/qcost/qcost-0242.csv',\n",
       " '/data/train-data/qcost/qcost-0238.csv',\n",
       " '/data/train-data/qcost/qcost-0246.csv',\n",
       " '/data/train-data/qcost/qcost-0253.csv',\n",
       " '/data/train-data/qcost/qcost-0250.csv',\n",
       " '/data/train-data/qcost/qcost-0195.csv',\n",
       " '/data/train-data/qcost/qcost-0223.csv',\n",
       " '/data/train-data/qcost/qcost-0199.csv',\n",
       " '/data/train-data/qcost/qcost-0203.csv',\n",
       " '/data/train-data/qcost/qcost-0227.csv',\n",
       " '/data/train-data/qcost/qcost-0211.csv',\n",
       " '/data/train-data/qcost/qcost-0207.csv',\n",
       " '/data/train-data/qcost/qcost-0231.csv',\n",
       " '/data/train-data/qcost/qcost-0215.csv',\n",
       " '/data/train-data/qcost/qcost-0235.csv',\n",
       " '/data/train-data/qcost/qcost-0219.csv',\n",
       " '/data/train-data/qcost/qcost-0243.csv',\n",
       " '/data/train-data/qcost/qcost-0239.csv',\n",
       " '/data/train-data/qcost/qcost-0247.csv',\n",
       " '/data/train-data/qcost/qcost-0251.csv',\n",
       " '/data/train-data/qcost/qcost-0254.csv',\n",
       " '/data/train-data/qcost/qcost-0255.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = os.path.join(config['io']['data_dir'], config['train']['dir'])\n",
    "train_files = glob.glob(os.path.join(config['io']['data_dir'], config['train']['dir'], '*.csv'))\n",
    "test_files = glob.glob(os.path.join(config['io']['data_dir'], config['test']['dir'], '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9416f80-b0f8-4151-9150-7489f2c04d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_dataset = EndureQDataSet(config, train_files)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff32379-80d9-413c-9021-aabad4dbe88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_dataset = EndureQDataSet(config, test_files)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96c4f60-1bfa-4620-b5b7-ce7415e2ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_job = TrainJob(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8882b8-a8fe-406b-9a06-537de7e42c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    config=config,\n",
    "    model=train_job.model,\n",
    "    optimizer=train_job.optimizer,\n",
    "    loss_fn=train_job.loss_fn,\n",
    "    train_data=train_dataloader,\n",
    "    test_data=test_dataloader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a4afc4-e11d-4137-a90b-4736a132fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 240.680634:  10%|█▌              | 102097/1048576 [02:37<24:21, 647.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/endure/notebook/data-gen/../../model/trainer.py:121\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEarly Stop: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_gradients_up\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mearly_stop_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m curr_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_loop()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/endure/notebook/data-gen/../../model/trainer.py:47\u001b[0m, in \u001b[0;36mTrainer._train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     46\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 47\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     49\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/endure/notebook/data-gen/../../model/trainer.py:27\u001b[0m, in \u001b[0;36mTrainer._train_step\u001b[0;34m(self, label, features)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, features) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(pred, label)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/endure/notebook/data-gen/../../model/kcost.py:33\u001b[0m, in \u001b[0;36mKCostModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(cate_inputs), start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x[:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_cont_vars\u001b[39m\u001b[38;5;124m'\u001b[39m]], out), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bac0a2-2774-4350-b688-b20a57f23aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
